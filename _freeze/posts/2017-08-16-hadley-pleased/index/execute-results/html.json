{
  "hash": "018e91c943403ec2cd60437a88220686",
  "result": {
    "markdown": "---\ntitle: \"Which RStudio blog posts “pleased” Hadley? A tidytext + web scraping analysis\"\nauthor: \"Davis Vaughan\"\ndate: '2017-08-16'\n---\n\n### Introduction\n\nAwhile back, I saw a conversation on twitter about how Hadley uses the word \"pleased\" very often when introducing a new blog post (I couldn't seem to find this tweet anymore. Can anyone help?).\nOut of curiousity, and to flex my R web scraping muscles a bit, I've decided to analyze the 240+ blog posts that RStudio has put out since 2011.\nThis post will do a few things:\n\n-   Scrape the RStudio blog archive page to construct URL links to each blog post\n-   Scrape the blog post text and metadata from each post\n-   Use a bit of `tidytext` for some exploratory analysis\n-   Perform a statistical test to compare Hadley's use of \"pleased\" to the other blog post authors\n\nSpoiler alert: Hadley uses \"pleased\" ALOT.\n\n### Required packages\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(rvest)\nlibrary(xml2)\n```\n:::\n\n### Extract the HTML from the RStudio blog archive\n\nTo be able to extract the text from each blog post, we first need to have a link to that blog post.\nLuckily, RStudio keeps an up to date archive page that we can scrape.\nUsing `xml2`, we can get the HTML off that page.\n\n::: {.cell}\n\n```{.r .cell-code}\narchive_page <- \"https://blog.rstudio.com/archives/\"\n\narchive_html <- read_html(archive_page)\n\n# Doesn't seem very useful...yet\narchive_html\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n{xml_document}\n<html lang=\"en-us\">\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\\n<meta charset=\"u ...\n[2] <body>\\n    <nav class=\"menu\"><svg version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xli ...\n```\n:::\n:::\n\nNow we use a bit of `rvest` magic combined with the HTML inspector in Chrome to figure out which elements contain the info we need (I also highly recommend [SelectorGadget](http://selectorgadget.com/) for this kind of work).\nLooking at the image below, you can see that all of the links are contained within the `main` tag as `a` tags (links).\n\n![](./img/html-inspector.png)\n\nThe code below extracts all of the links, and then adds the prefix containing the base URL of the site.\n\n::: {.cell}\n\n```{.r .cell-code}\nlinks <- archive_html %>%\n  \n  # Only the \"main\" body of the archive\n  html_nodes(\"main\") %>%\n  \n  # Grab any node that is a link\n  html_nodes(\"a\") %>%\n  \n  # Extract the hyperlink reference from those link tags\n  # The hyperlink is an attribute as opposed to a node\n  html_attr(\"href\") %>%\n  \n  # Prefix them all with the base URL\n  paste0(\"http://blog.rstudio.com\", .)\n\nhead(links)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"http://blog.rstudio.com/2017/08/25/rstudio-conf-2018-early-bird-pricing/\"    \n[2] \"http://blog.rstudio.com/2017/08/22/rstudio-v1-1-preview-object-explorer/\"    \n[3] \"http://blog.rstudio.com/2017/08/18/google-cloud-platform/\"                   \n[4] \"http://blog.rstudio.com/2017/08/16/rstudio-preview-connections/\"             \n[5] \"http://blog.rstudio.com/2017/08/15/contributed-talks-diversity-scholarships/\"\n[6] \"http://blog.rstudio.com/2017/08/15/shiny-1-0-4/\"                             \n```\n:::\n:::\n\n### HTML from each blog post\n\nNow that we have every link, we're ready to extract the HTML from each individual blog post.\nTo make things more manageable, we start by creating a tibble, and then using the `mutate + map` combination to created a column of XML Nodesets (we will use this combination a lot).\nEach nodeset contains the HTML for that blog post (exactly like the HTML for the archive page).\n\n::: {.cell}\n\n```{.r .cell-code}\nblog_data <- tibble(links)\n\nblog_data <- blog_data %>%\n  mutate(main = map(\n                    # Iterate through every link\n                    .x = links, \n                    \n                    # For each link, read the HTML for that page, and return the main section \n                    .f = ~read_html(.) %>%\n                            html_nodes(\"main\")\n                    )\n         )\n\nblog_data$main[1]\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n{xml_nodeset (1)}\n[1] <main><div class=\"article-meta\">\\n<h1><span class=\"title\">Newer to R? rstudio::conf 2018 is fo ...\n```\n:::\n:::\n\n### Meta information\n\nBefore extracting the blog post itself, lets grab the meta information about each post, specifically:\n\n-   Author\n-   Title\n-   Date\n-   Category\n-   Tags\n\nIn the exploratory analysis, we will use author and title, but the other information might be useful for future analysis.\n\nLooking at the first blog post, the Author, Date, and Title are all HTML class names that we can feed into `rvest` to extract that information.\n\n![](./img/date-author-title.png)\n\nIn the code below, an example of extracting the author information is shown.\nTo select a HTML class (like \"author\") as opposed to a tag (like \"main\"), we have to put a period in front of the class name.\nOnce the html node we are interested in has been identified, we can extract the text for that node using `html_text()`.\n\n::: {.cell}\n\n```{.r .cell-code}\nblog_data$main[[1]] %>%\n  html_nodes(\".author\") %>%\n  html_text()\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Roger Oberg\"\n```\n:::\n:::\n\nTo scale up to grab the author for all posts, we use `map_chr()` since we want a character of the author's name returned.\n\n::: {.cell}\n\n```{.r .cell-code}\nmap_chr(.x = blog_data$main,\n        .f = ~html_nodes(.x, \".author\") %>%\n                html_text()) %>%\n  head(10)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Roger Oberg\"        \"Kevin Ushey\"        \"Roger Oberg\"       \n [4] \"Jonathan McPherson\" \"Hadley Wickham\"     \"Winston Chang\"     \n [7] \"Gary Ritchie\"       \"Roger Oberg\"        \"Jeff Allen\"        \n[10] \"Javier Luraschi\"   \n```\n:::\n:::\n\nFinally, notice that if we switch `\".author\"` with `\".title\"` or `\".date\"` then we can grab that information as well.\nThis kind of thinking means that we should create a function for extracting these pieces of information!\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_info <- function(html, class_name) {\n  map_chr(\n          # Given the list of main HTMLs\n          .x = html,\n          \n          # Extract the text we are interested in for each one \n          .f = ~html_nodes(.x, class_name) %>%\n                  html_text())\n}\n\n# Extract the data\nblog_data <- blog_data %>%\n  mutate(\n     author = extract_info(main, \".author\"),\n     title  = extract_info(main, \".title\"),\n     date   = extract_info(main, \".date\")\n    )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(blog_data, author, date)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 253 × 2\n   author             date      \n   <chr>              <chr>     \n 1 Roger Oberg        2017-08-25\n 2 Kevin Ushey        2017-08-22\n 3 Roger Oberg        2017-08-18\n 4 Jonathan McPherson 2017-08-16\n 5 Hadley Wickham     2017-08-15\n 6 Winston Chang      2017-08-15\n 7 Gary Ritchie       2017-08-11\n 8 Roger Oberg        2017-08-10\n 9 Jeff Allen         2017-08-03\n10 Javier Luraschi    2017-07-31\n# … with 243 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(blog_data, title)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 253 × 1\n   title                                                                        \n   <chr>                                                                        \n 1 Newer to R? rstudio::conf 2018 is for you! Early bird pricing ends August 31.\n 2 RStudio v1.1 Preview - Object Explorer                                       \n 3 RStudio Server Pro is ready for BigQuery on the Google Cloud Platform        \n 4 RStudio 1.1 Preview - Data Connections                                       \n 5 rstudio::conf(2018): Contributed talks, e-posters, and diversity scholarships\n 6 Shiny 1.0.4                                                                  \n 7 RStudio v1.1 Preview: Terminal                                               \n 8 Building tidy tools workshop                                                 \n 9 RStudio Connect v1.5.4 - Now Supporting Plumber!                             \n10 sparklyr 0.6                                                                 \n# … with 243 more rows\n```\n:::\n:::\n\n### Categories and tags\n\nThe other bits of meta data that might be interesting are the categories and tags that the post falls under.\nThis is a little bit more involved, because both the categories and tags fall under the same class, `\".terms\"`.\nTo separate them, we need to look into the href to see if the information is either a tag or a category (href = \"/categories/\" VS href = \"/tags/\").\n\n![](./img/cat-tag.png)\n\nThe function below extracts either the categories or the tags, depending on the argument, by:\n\n-   Extracting the `\".terms\"` class, and then all of the links inside of it (`a` tags).\n-   Checking each link to see if the hyperlink reference contains \"categories\" or \"tags\" depending on the one that we are interested in. If it does, it returns the text corresponding to that link, otherwise it returns NAs which are then removed.\n\nThe final step results in two list columns containing character vectors of varying lengths corresponding to the categories and tags of each post.\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_tag_or_cat <- function(html, info_name) {\n  \n  # Extract the links under the terms class\n  cats_and_tags <- map(.x = html, \n                       .f = ~html_nodes(.x, \".terms\") %>%\n                              html_nodes(\"a\"))\n  \n  # For each link, if the href contains the word categories/tags \n  # return the text corresponding to that link\n  map(cats_and_tags, \n    ~if_else(condition = grepl(info_name, html_attr(.x, \"href\")), \n             true      = html_text(.x), \n             false     = NA_character_) %>%\n      .[!is.na(.)])\n}\n\n# Apply our new extraction function\nblog_data <- blog_data %>%\n  mutate(\n    categories = extract_tag_or_cat(main, \"categories\"),\n    tags       = extract_tag_or_cat(main, \"tags\")\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(blog_data, categories, tags)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 253 × 2\n   categories tags     \n   <list>     <list>   \n 1 <chr [3]>  <chr [1]>\n 2 <chr [1]>  <chr [0]>\n 3 <chr [2]>  <chr [4]>\n 4 <chr [1]>  <chr [0]>\n 5 <chr [1]>  <chr [0]>\n 6 <chr [2]>  <chr [0]>\n 7 <chr [1]>  <chr [3]>\n 8 <chr [3]>  <chr [8]>\n 9 <chr [3]>  <chr [2]>\n10 <chr [1]>  <chr [3]>\n# … with 243 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nblog_data %>%\n  filter(title == \"Building tidy tools workshop\") %>%\n  pull(categories)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] \"Packages\"  \"tidyverse\" \"Training\" \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nblog_data %>%\n  filter(title == \"Building tidy tools workshop\") %>%\n  pull(tags)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] \"Advanced R\"       \"data science\"     \"ggplot2\"          \"Hadley Wickham\"  \n[5] \"R\"                \"RStudio Workshop\" \"r training\"       \"tutorial\"        \n```\n:::\n:::\n\n### The blog post itself\n\nFinally, to extract the blog post itself, we can notice that each piece of text in the post is inside of a paragraph tag (`p`).\nBeing careful to avoid the `\".terms\"` class that contained the categories and tags, which also happens to be in a paragraph tag, we can extract the full blog posts.\nTo ignore the `\".terms\"` class, use the `:not()` selector.\n\n::: {.cell}\n\n```{.r .cell-code}\nblog_data <- blog_data %>%\n  mutate(\n    text = map_chr(main, ~html_nodes(.x, \"p:not(.terms)\") %>%\n                 html_text() %>%\n                 # The text is returned as a character vector. \n                 # Collapse them all into 1 string.\n                 paste0(collapse = \" \"))\n  )\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(blog_data, text)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 253 × 1\n   text                                                                         \n   <chr>                                                                        \n 1 \"Immersion is among the most effective ways to learn any language. Immersing…\n 2 \"Today, we’re continuing our blog series on new features in RStudio 1.1. If …\n 3 \"RStudio is excited to announce the availability of RStudio Server Pro on th…\n 4 \"Today, we’re continuing our blog series on new features in RStudio 1.1. If …\n 5 \"rstudio::conf, the conference on all things R and RStudio, will take place …\n 6 \"Shiny 1.0.4 is now available on CRAN. To install it, run: For most Shiny us…\n 7 \"Today we’re excited to announce availability of our first Preview Release f…\n 8 \"Have you embraced the tidyverse? Do you now want to expand it to meet your …\n 9 \"We’re thrilled to announce support for hosting Plumber APIs in RStudio Conn…\n10 \"We’re excited to announce a new release of the sparklyr package, available …\n# … with 243 more rows\n```\n:::\n:::\n\n### Who writes the most posts?\n\nNow that we have all of this data, what can we do with it?\nTo start with, who writes the most posts?\n\n::: {.cell}\n\n```{.r .cell-code}\nblog_data %>%\n  group_by(author) %>%\n  summarise(count = n()) %>%\n  mutate(author = reorder(author, count)) %>%\n  \n  # Create a bar graph of author counts\n  ggplot(mapping = aes(x = author, y = count)) + \n  geom_col() +\n  coord_flip() +\n  labs(title    = \"Who writes the most RStudio blog posts?\",\n       subtitle = \"By a huge margin, Hadley!\") +\n  # Shoutout to Bob Rudis for the always fantastic themes\n  hrbrthemes::theme_ipsum(grid = \"Y\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=792}\n:::\n:::\n\n### Tidytext\n\nI've never used `tidytext` before today, but to get our feet wet, let's create a tokenized tidy version of our data.\nBy using `unnest_tokens()` the data will be reshaped to a long format holding 1 word per row, for each blog post.\nThis tidy format lends itself to all manner of analysis, and a number of them are outlined in Julia Silge and David Robinson's [Text Mining with R](http://tidytextmining.com/).\n\n::: {.cell}\n\n```{.r .cell-code}\ntokenized_blog <- blog_data %>%\n  mutate(short_title = str_sub(title, end = 15)) %>%\n  select(title, short_title, author, date, text) %>%\n  unnest_tokens(output = word, input = text)\n\nselect(tokenized_blog, short_title, word)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 85,761 × 2\n   short_title     word     \n   <chr>           <chr>    \n 1 Newer to R? rst immersion\n 2 Newer to R? rst is       \n 3 Newer to R? rst among    \n 4 Newer to R? rst the      \n 5 Newer to R? rst most     \n 6 Newer to R? rst effective\n 7 Newer to R? rst ways     \n 8 Newer to R? rst to       \n 9 Newer to R? rst learn    \n10 Newer to R? rst any      \n# … with 85,751 more rows\n```\n:::\n:::\n\n### Remove stop words\n\nA number of words like \"a\" or \"the\" are included in the blog that don't really add value to a text analysis.\nThese stop words can be removed using an `anti_join()` with the `stop_words` dataset that comes with `tidytext`.\nAfter removing stop words, the number of rows was cut in half!\n\n::: {.cell}\n\n```{.r .cell-code}\ntokenized_blog <- tokenized_blog %>%\n  anti_join(stop_words, by = \"word\") %>%\n  arrange(desc(date))\n\nselect(tokenized_blog, short_title, word)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 40,315 × 2\n   short_title     word     \n   <chr>           <chr>    \n 1 Newer to R? rst immersion\n 2 Newer to R? rst effective\n 3 Newer to R? rst learn    \n 4 Newer to R? rst language \n 5 Newer to R? rst immersing\n 6 Newer to R? rst advanced \n 7 Newer to R? rst users    \n 8 Newer to R? rst improve  \n 9 Newer to R? rst language \n10 Newer to R? rst rare     \n# … with 40,305 more rows\n```\n:::\n:::\n\n### Top 15 words overall\n\nOut of pure curiousity, what are the top 15 words for all of the blog posts?\n\n::: {.cell}\n\n```{.r .cell-code}\ntokenized_blog %>%\n  count(word, sort = TRUE) %>%\n  slice(1:15) %>%\n  mutate(word = reorder(word, n)) %>%\n  \n  ggplot(aes(word, n)) +\n  geom_col() + \n  coord_flip() + \n  labs(title = \"Top 15 words overall\") +\n  hrbrthemes::theme_ipsum(grid = \"Y\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-1.png){width=792}\n:::\n:::\n\n### Is Hadley more \"pleased\" than everyone else?\n\nAs mentioned at the beginning of the post, Hadley apparently uses the word \"pleased\" in his blog posts an above average number of times.\nCan we verify this statistically?\n\n*Our null hypothesis is that the proportion of blog posts that use the word \"pleased\" written by Hadley is less than or equal to the proportion of those written by the rest of the RStudio team.*\n\nMore simply, our null is that Hadley uses \"pleased\" less than or the same as the rest of the team.\n\nLet's check visually to compare the two groups of posts.\n\n::: {.cell}\n\n```{.r .cell-code}\npleased <- tokenized_blog %>%\n  \n  # Group by blog post\n  group_by(title) %>%\n  \n  # If the blog post contains \"pleased\" put yes, otherwise no\n  # Add a column checking if the author was Hadley\n  mutate(\n    contains_pleased = case_when(\n      \"pleased\" %in% word ~ \"Yes\",\n      TRUE                ~ \"No\"),\n    \n    is_hadley = case_when(\n      author == \"Hadley Wickham\" ~ \"Hadley\",\n      TRUE                       ~ \"Not Hadley\")\n    ) %>%\n  \n  # Remove all duplicates now\n  distinct(title, contains_pleased, is_hadley)\n\npleased %>%\n  ggplot(aes(x = contains_pleased)) +\n  geom_bar() +\n  facet_wrap(~is_hadley, scales = \"free_y\") +\n  labs(title    = \"Does this blog post contain 'pleased'?\", \n       subtitle = \"Nearly half of Hadley's do!\",\n       x        = \"Contains 'pleased'\",\n       y        = \"Count\") +\n  hrbrthemes::theme_ipsum(grid = \"Y\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-27-1.png){width=792}\n:::\n:::\n\n### Is there a statistical difference here?\n\nTo check if there is a statistical difference, we will use a test for difference in proportions contained in the R function, `prop.test()`.\nFirst, we need a continency table of the counts.\nGiven the current form of our dataset, this isn't too hard with the `table()` function from base R.\n\n::: {.cell}\n\n```{.r .cell-code}\ncontingency_table <- pleased %>%\n  ungroup() %>%\n  select(is_hadley, contains_pleased) %>%\n  # Order the factor so Yes is before No for easy interpretation\n  mutate(contains_pleased = factor(contains_pleased, levels = c(\"Yes\", \"No\"))) %>%\n  table()\n\ncontingency_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            contains_pleased\nis_hadley    Yes  No\n  Hadley      43  45\n  Not Hadley  17 148\n```\n:::\n:::\n\nFrom our null hypothesis, we want to perform a *one sided* test.\nThe alternative to our null is that Hadley uses \"pleased\" *more* than the rest of the RStudio team.\nFor this reason, we specify `alternative = \"greater\"`.\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_prop <- contingency_table %>%\n  prop.test(alternative = \"greater\")\n\ntest_prop\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\t2-sample test for equality of proportions with continuity correction\n\ndata:  .\nX-squared = 45.063, df = 1, p-value = 9.541e-12\nalternative hypothesis: greater\n95 percent confidence interval:\n 0.2809899 1.0000000\nsample estimates:\n   prop 1    prop 2 \n0.4886364 0.1030303 \n```\n:::\n:::\n\nWe could also tidy this up with `broom` if we were inclined to.\n\n::: {.cell}\n\n```{.r .cell-code}\nbroom::tidy(test_prop)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 9\n  estimate1 estimate2 statistic  p.value parameter conf.low conf.high method    \n      <dbl>     <dbl>     <dbl>    <dbl>     <dbl>    <dbl>     <dbl> <chr>     \n1     0.489     0.103      45.1 9.54e-12         1    0.281         1 2-sample …\n# … with 1 more variable: alternative <chr>\n```\n:::\n:::\n\n### Test conclusion\n\n-   48.86% of Hadley's posts contain \"pleased\"\n-   10.3% of the rest of the RStudio team's posts contain \"pleased\"\n-   With a p-value of 9.5414477\\times 10^{-12}, we reject the null that Hadley uses \"pleased\" less than or the same as the rest of the team. The evidence supports the idea that he has a much higher preference for it!\n\nHadley uses \"pleased\" quite a bit!\n\n### Conclusion\n\nThis post used a lot of different tools, but that's the beauty of having over 12,000 R packages at our disposal.\nI think that this dataset could be used in a number of other ways, so be on the lookout for more posts!",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}